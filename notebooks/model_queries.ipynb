{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38b46b6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 1: Imports\n",
    "import sys\n",
    "sys.path.append(\"..\")  # allow importing from src\n",
    "from src.utils import load_student_files, save_model_results, ensure_dir\n",
    "from pathlib import Path\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Model clients\n",
    "import openai\n",
    "import anthropic\n",
    "import google.generativeai as genai\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API keys\n",
    "load_dotenv()\n",
    "OPENAI_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "GOOGLE_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "ANTHROPIC_KEY = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "PERPLEXITY_KEY = os.getenv(\"PERPLEXITY_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b695410",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 2: Paths\n",
    "DATA_DIR = Path(\"../data/processed_submissions\")\n",
    "RESULTS_DIR = Path(\"../results/raw\")\n",
    "ensure_dir(RESULTS_DIR)\n",
    "\n",
    "MODELS = [\"chatgpt\", \"gemini\", \"claude\", \"perplexity\", \"starcoder\"]\n",
    "\n",
    "\n",
    "# StarCoder setup\n",
    "STARCODER_MODEL = \"bigcode/starcoder\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(STARCODER_MODEL)\n",
    "model = AutoModelForCausalLM.from_pretrained(STARCODER_MODEL)\n",
    "\n",
    "# Helper functions for models\n",
    "\n",
    "def query_chatgpt(code):\n",
    "    openai.api_key = OPENAI_KEY\n",
    "    prompt = f\"Analyze this Python code and generate three reflective, non-solution prompts:\\n\\n{code}\"\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=500\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n",
    "\n",
    "def query_gemini(code):\n",
    "    genai.configure(api_key=GOOGLE_KEY)\n",
    "    prompt = f\"Analyze this Python code and generate three reflective, non-solution prompts:\\n\\n{code}\"\n",
    "    response = genai.chat.create(\n",
    "        model=\"gemini-1.5\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response.last_response\n",
    "\n",
    "def query_claude(code):\n",
    "    client = anthropic.Client(ANTHROPIC_KEY)\n",
    "    prompt = f\"Analyze this Python code and generate three reflective, non-solution prompts:\\n\\n{code}\"\n",
    "    response = client.completions.create(\n",
    "        model=\"claude-2\",\n",
    "        prompt=prompt,\n",
    "        max_tokens_to_sample=500\n",
    "    )\n",
    "    return response.completion\n",
    "\n",
    "def query_perplexity(code):\n",
    "    # Placeholder for actual API call\n",
    "    return f\"Perplexity AI response placeholder for code:\\n{code[:50]}...\"\n",
    "\n",
    "def query_starcoder(code):\n",
    "    inputs = tokenizer(code, return_tensors=\"pt\")\n",
    "    outputs = model.generate(**inputs, max_new_tokens=150)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1244a7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 3: Load Student Submissions\n",
    "submissions = load_student_files(data_dir=DATA_DIR)\n",
    "print(f\"Loaded {len(submissions)} student submissions.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a925a524",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 4: Query All Models\n",
    "for filename, code in submissions.items():\n",
    "    results = {\n",
    "        \"chatgpt\": query_chatgpt(code),\n",
    "        \"gemini\": query_gemini(code),\n",
    "        \"claude\": query_claude(code),\n",
    "        \"perplexity\": query_perplexity(code),\n",
    "        \"starcoder\": query_starcoder(code)\n",
    "    }\n",
    "\n",
    "    output_file = save_model_results(results, filename)\n",
    "    print(f\"{filename} processed and saved to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
